{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":169835,"sourceType":"datasetVersion","datasetId":74977},{"sourceId":1508992,"sourceType":"datasetVersion","datasetId":888463},{"sourceId":8469272,"sourceType":"datasetVersion","datasetId":5049828},{"sourceId":12687167,"sourceType":"datasetVersion","datasetId":8017557}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import stats\nimport re\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom scipy.stats import boxcox\nfrom scipy.stats import yeojohnson\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.419334Z","iopub.execute_input":"2025-08-11T17:45:09.420191Z","iopub.status.idle":"2025-08-11T17:45:09.430650Z","shell.execute_reply.started":"2025-08-11T17:45:09.420165Z","shell.execute_reply":"2025-08-11T17:45:09.429630Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Week 2 Briefing\nThis week, our goal is to learn the basics of statistical tools required for data engineering. There are four modules as part of this week's learning goals:\n* Data cleaning\n* Statistical queries on dataset\n* Data visualization\n* Data transformation","metadata":{}},{"cell_type":"markdown","source":"# Module 1: Data cleaning\nPackages used: pandas, numpy, re, sklearn.impute\nSteps: EDA, Missing data handling, removing duplicates, formatting and data type, string cleaning and standardization, outliers, validation, text cleaning.","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf = pd.read_csv('/kaggle/input/dirty-dataset-to-practice-data-cleaning/my_file (1).csv')\ndf.head() #preview first few rows to understand the structure\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.432253Z","iopub.execute_input":"2025-08-11T17:45:09.432567Z","iopub.status.idle":"2025-08-11T17:45:09.463392Z","shell.execute_reply.started":"2025-08-11T17:45:09.432545Z","shell.execute_reply":"2025-08-11T17:45:09.462499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.info() #concise summary of the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.464561Z","iopub.execute_input":"2025-08-11T17:45:09.464819Z","iopub.status.idle":"2025-08-11T17:45:09.475154Z","shell.execute_reply.started":"2025-08-11T17:45:09.464799Z","shell.execute_reply":"2025-08-11T17:45:09.474212Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns #list the columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.476164Z","iopub.execute_input":"2025-08-11T17:45:09.476614Z","iopub.status.idle":"2025-08-11T17:45:09.498599Z","shell.execute_reply.started":"2025-08-11T17:45:09.476576Z","shell.execute_reply":"2025-08-11T17:45:09.497145Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Exploratory data analysis: identify missing values, duplicates, data types, summary\nprint(df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.500945Z","iopub.execute_input":"2025-08-11T17:45:09.501537Z","iopub.status.idle":"2025-08-11T17:45:09.518709Z","shell.execute_reply.started":"2025-08-11T17:45:09.501506Z","shell.execute_reply":"2025-08-11T17:45:09.517841Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.duplicated().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.519610Z","iopub.execute_input":"2025-08-11T17:45:09.519879Z","iopub.status.idle":"2025-08-11T17:45:09.544542Z","shell.execute_reply.started":"2025-08-11T17:45:09.519860Z","shell.execute_reply":"2025-08-11T17:45:09.543558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.describe(include='all'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.545499Z","iopub.execute_input":"2025-08-11T17:45:09.545793Z","iopub.status.idle":"2025-08-11T17:45:09.583187Z","shell.execute_reply.started":"2025-08-11T17:45:09.545770Z","shell.execute_reply":"2025-08-11T17:45:09.582307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df.dtypes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.584021Z","iopub.execute_input":"2025-08-11T17:45:09.584292Z","iopub.status.idle":"2025-08-11T17:45:09.591258Z","shell.execute_reply.started":"2025-08-11T17:45:09.584267Z","shell.execute_reply":"2025-08-11T17:45:09.590122Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#text cleaning using anonymous function lambda\ndf[\"Ref.\"]= df[\"Ref.\"].apply(lambda x : re.sub(r\"[^a-zA-Z0-9]\" , \"\" , x))\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.592520Z","iopub.execute_input":"2025-08-11T17:45:09.592838Z","iopub.status.idle":"2025-08-11T17:45:09.620794Z","shell.execute_reply.started":"2025-08-11T17:45:09.592809Z","shell.execute_reply":"2025-08-11T17:45:09.620019Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print([{col} for col in df.columns])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.630347Z","iopub.execute_input":"2025-08-11T17:45:09.630702Z","iopub.status.idle":"2025-08-11T17:45:09.636546Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#remove unwarranted spaces\ndf.columns = df.columns.str.replace('\\xa0', ' ', regex=False)\nprint([col for col in df.columns])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.638323Z","iopub.execute_input":"2025-08-11T17:45:09.638684Z","iopub.status.idle":"2025-08-11T17:45:09.659288Z","shell.execute_reply.started":"2025-08-11T17:45:09.638654Z","shell.execute_reply":"2025-08-11T17:45:09.658118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#cleaning text\ndef clean_text(text):\n    text = re.sub(r\"\\[\\s*.*?\\s*\\]\", \"\" , text)\n    text = re.sub(r\"[^a-zA-Z0-9]\", \"\" , text)\n    return text \ncolumns = [\"Actual gross\" , \"Actual gross(in 2022 dollars)\" , \"Average gross\"]\nfor column in columns:\n    df[column] = df[column].apply(clean_text)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.661027Z","iopub.execute_input":"2025-08-11T17:45:09.661420Z","iopub.status.idle":"2025-08-11T17:45:09.702129Z","shell.execute_reply.started":"2025-08-11T17:45:09.661390Z","shell.execute_reply":"2025-08-11T17:45:09.700927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#cleaning texts\ndef clean_peak(text):\n    if not pd.isna(text):\n        text =  re.sub(r\"\\[\\s*.*?\\s*\\]\", \"\" , text)\n    return text\ncolumns = [\"Peak\" , \"All Time Peak\"]\nfor column in columns:\n    df[column] = df[column].apply(clean_peak)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.704540Z","iopub.execute_input":"2025-08-11T17:45:09.705243Z","iopub.status.idle":"2025-08-11T17:45:09.731532Z","shell.execute_reply.started":"2025-08-11T17:45:09.705210Z","shell.execute_reply":"2025-08-11T17:45:09.730402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#remove wierd characters from the strings\ndef clean_title(text):\n    text =  re.sub(r\"[^a-zA-Z ]\", \"\" , text)\n    return text\ndf[\"Tour title\"] = df[\"Tour title\"].apply(clean_title)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.732542Z","iopub.execute_input":"2025-08-11T17:45:09.733039Z","iopub.status.idle":"2025-08-11T17:45:09.750446Z","shell.execute_reply.started":"2025-08-11T17:45:09.733004Z","shell.execute_reply":"2025-08-11T17:45:09.749557Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.751797Z","iopub.execute_input":"2025-08-11T17:45:09.752189Z","iopub.status.idle":"2025-08-11T17:45:09.778242Z","shell.execute_reply.started":"2025-08-11T17:45:09.752159Z","shell.execute_reply":"2025-08-11T17:45:09.777336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Fixing inconsistent data\ndf[\"Ref.\"] = df[\"Ref.\"].replace(\"1516\" , \"16\")\ndf[\"Ref.\"] = df[\"Ref.\"].replace(\"d\" , \"5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.779399Z","iopub.execute_input":"2025-08-11T17:45:09.779729Z","iopub.status.idle":"2025-08-11T17:45:09.799267Z","shell.execute_reply.started":"2025-08-11T17:45:09.779706Z","shell.execute_reply":"2025-08-11T17:45:09.798294Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.800370Z","iopub.execute_input":"2025-08-11T17:45:09.800746Z","iopub.status.idle":"2025-08-11T17:45:09.829208Z","shell.execute_reply.started":"2025-08-11T17:45:09.800716Z","shell.execute_reply":"2025-08-11T17:45:09.828245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Fixing numerical columns data type; convert to float\nnumeric_cols = [\"Actual gross\" , \"Actual gross(in 2022 dollars)\" \n                , \"Average gross\" , \"Shows\" , \"Ref.\" , \"Peak\" , \"All Time Peak\"]\nfor cols in numeric_cols :\n    df[cols] = df[cols].astype(\"float\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.830165Z","iopub.execute_input":"2025-08-11T17:45:09.830547Z","iopub.status.idle":"2025-08-11T17:45:09.849772Z","shell.execute_reply.started":"2025-08-11T17:45:09.830520Z","shell.execute_reply":"2025-08-11T17:45:09.848820Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.852905Z","iopub.execute_input":"2025-08-11T17:45:09.853190Z","iopub.status.idle":"2025-08-11T17:45:09.882893Z","shell.execute_reply.started":"2025-08-11T17:45:09.853170Z","shell.execute_reply":"2025-08-11T17:45:09.882008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#drop columns with too many missing values\ndf = df.drop([\"All Time Peak\" , \"Peak\"] , axis =1)\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.884177Z","iopub.execute_input":"2025-08-11T17:45:09.884818Z","iopub.status.idle":"2025-08-11T17:45:09.912254Z","shell.execute_reply.started":"2025-08-11T17:45:09.884794Z","shell.execute_reply":"2025-08-11T17:45:09.911076Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Final validation\nprint(df.isnull().sum())\nprint(df.describe(include='all'))\nprint(df.head())\n\n# Save cleaned version\ndf.to_csv('dirty_dataset_cleaned.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.913202Z","iopub.execute_input":"2025-08-11T17:45:09.913528Z","iopub.status.idle":"2025-08-11T17:45:09.955081Z","shell.execute_reply.started":"2025-08-11T17:45:09.913501Z","shell.execute_reply":"2025-08-11T17:45:09.953878Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Module 2: Querying data, statistical properties and error\nPackages used: pandas","metadata":{}},{"cell_type":"code","source":"# Load data\nimport pandas as pd\ndf = pd.read_csv(\"/kaggle/input/students-performance-in-exams/StudentsPerformance.csv\")\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.956093Z","iopub.execute_input":"2025-08-11T17:45:09.956413Z","iopub.status.idle":"2025-08-11T17:45:09.971721Z","shell.execute_reply.started":"2025-08-11T17:45:09.956385Z","shell.execute_reply":"2025-08-11T17:45:09.970815Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Exploration: looking for numerical data\nnumeric_cols = ['math score', 'reading score', 'writing score']\ndf[numeric_cols].describe()\n\n#Exercise 1: Add a new column that computes average score of a student across the three subjects","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.972608Z","iopub.execute_input":"2025-08-11T17:45:09.972941Z","iopub.status.idle":"2025-08-11T17:45:09.993308Z","shell.execute_reply.started":"2025-08-11T17:45:09.972898Z","shell.execute_reply":"2025-08-11T17:45:09.992360Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# average score column added for the 3 subjects\ndf['average score'] = df[['math score', 'reading score', 'writing score']].mean(axis=1)\n\n#updated dataframe\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:09.994713Z","iopub.execute_input":"2025-08-11T17:45:09.995066Z","iopub.status.idle":"2025-08-11T17:45:10.009088Z","shell.execute_reply.started":"2025-08-11T17:45:09.995036Z","shell.execute_reply":"2025-08-11T17:45:10.008129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Mean, mode and median for math score\nprint(\"Mean Math Score:\", df['math score'].mean())\nprint(\"Median Math Score:\", df['math score'].median())\nprint(\"Mode Math Score:\", df['math score'].mode()[0])\n\n#Exercise 2: Compute mean, median, mode for reading and writing scores.\n# Mean, mode and median for reading score\nprint(\"Mean reading Score:\", df['reading score'].mean())\nprint(\"Median reading Score:\", df['reading score'].median())\nprint(\"Mode reading Score:\", df['reading score'].mode()[0])\n# Mean, mode and median for writing score\nprint(\"Mean writing Score:\", df['writing score'].mean())\nprint(\"Median writing Score:\", df['writing score'].median())\nprint(\"Mode writing Score:\", df['writing score'].mode()[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:10.010268Z","iopub.execute_input":"2025-08-11T17:45:10.011165Z","iopub.status.idle":"2025-08-11T17:45:10.030932Z","shell.execute_reply.started":"2025-08-11T17:45:10.011140Z","shell.execute_reply":"2025-08-11T17:45:10.029377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['math score'][1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:10.031963Z","iopub.execute_input":"2025-08-11T17:45:10.032414Z","iopub.status.idle":"2025-08-11T17:45:10.061192Z","shell.execute_reply.started":"2025-08-11T17:45:10.032380Z","shell.execute_reply":"2025-08-11T17:45:10.059705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Measuring spread of data\nprint(\"Standard Deviation (Math):\", df['math score'].std())\nprint(\"Variance (Math):\", df['math score'].var())\nprint(\"Range (Math):\", df['math score'].max() - df['math score'].min())\n\n#Exercise 3: Repeat above steps for other subjects. What do you infer about subject difficulty?\n\n#reading score analysis\nprint(\"Standard Deviation (reading):\", df['reading score'].std())\nprint(\"Variance (reading):\", df['reading score'].var())\nprint(\"Range (reading):\", df['reading score'].max() - df['reading score'].min())\n#writing score analysis\nprint(\"Standard Deviation (writing):\", df['writing score'].std())\nprint(\"Variance (writing):\", df['writing score'].var())\nprint(\"Range (writing):\", df['writing score'].max() - df['writing score'].min())\n\n#calculating the std deviation\nstd_math = df['math score'].std()\nstd_reading = df['reading score'].std()\nstd_writing = df['writing score'].std()\n\nstd_dict = {\n    'Math': std_math,\n    'Reading': std_reading,\n    'Writing': std_writing\n}\n\nmost_difficult = max(std_dict, key=std_dict.get)\n\nprint(\"Most difficult subject based on std:\", most_difficult)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:10.062024Z","iopub.execute_input":"2025-08-11T17:45:10.062345Z","iopub.status.idle":"2025-08-11T17:45:10.084654Z","shell.execute_reply.started":"2025-08-11T17:45:10.062316Z","shell.execute_reply":"2025-08-11T17:45:10.083004Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Module 3: Data visualization \nPackages used: seaborn, matplotlib ","metadata":{}},{"cell_type":"code","source":"import seaborn as sns \nimport matplotlib.pyplot as plt \nimport pandas as pd \n\n# Math scores\nsns.histplot(df['math score'], kde=True)\nplt.axvline(df['math score'].mean(), color='red', linestyle='--', label='Mean')\nplt.axvline(df['math score'].median(), color='green', linestyle='--', label='Median')\nplt.legend()\nplt.title(\"Distribution of Math Scores\")\nplt.show()\n\n# Reading scores\nsns.histplot(df['reading score'], kde=True)\nplt.axvline(df['reading score'].mean(), color='red', linestyle='--', label='Mean')\nplt.axvline(df['reading score'].median(), color='green', linestyle='--', label='Median')\nplt.legend()\nplt.title(\"Distribution of Reading Scores\")\nplt.show()\n\n# Writing scores\nsns.histplot(df['writing score'], kde=True)\nplt.axvline(df['writing score'].mean(), color='red', linestyle='--', label='Mean')\nplt.axvline(df['writing score'].median(), color='green', linestyle='--', label='Median')\nplt.legend()\nplt.title(\"Distribution of Writing Scores\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:10.086221Z","iopub.execute_input":"2025-08-11T17:45:10.086662Z","iopub.status.idle":"2025-08-11T17:45:10.947542Z","shell.execute_reply.started":"2025-08-11T17:45:10.086627Z","shell.execute_reply":"2025-08-11T17:45:10.946471Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Comarisons using visualization\n#Exercise 5: Try changing legends, title, axis labels\nsns.boxplot(x='test preparation course', y='math score', hue='gender', data=df)\nplt.title(\"Math Score vs Test Preparation by Gender\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:10.948797Z","iopub.execute_input":"2025-08-11T17:45:10.949553Z","iopub.status.idle":"2025-08-11T17:45:11.222377Z","shell.execute_reply.started":"2025-08-11T17:45:10.949522Z","shell.execute_reply":"2025-08-11T17:45:11.221426Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.displot(df['math score'], kde=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:11.223412Z","iopub.execute_input":"2025-08-11T17:45:11.223738Z","iopub.status.idle":"2025-08-11T17:45:11.580704Z","shell.execute_reply.started":"2025-08-11T17:45:11.223711Z","shell.execute_reply":"2025-08-11T17:45:11.579818Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Module 3.1: Generating a normal distribution \n* np.random.normal(loc=mu, scale=sigma, size=n) generates random numbers from a normal (Gaussian) distribution.\n* plt.hist(..., density=True) makes the histogram show a probability density, not just raw counts.\n* The red line overlays the theoretical probability density function (PDF) for comparison.","metadata":{}},{"cell_type":"code","source":"# Parameters for the normal distribution\nmu = 0       # Mean\nsigma = 1    # Standard deviation\nn = 10000    # Number of samples\n\n# Generate random samples from a normal distribution\ndata = np.random.normal(loc=mu, scale=sigma, size=n)\n\n# Plot histogram of the data\nplt.figure(figsize=(8, 5))\nplt.hist(data, bins=50, density=True, alpha=0.6, color='skyblue', edgecolor='black')\n\n# Plot the theoretical normal distribution curve\nfrom scipy.stats import norm\nx = np.linspace(mu - 4*sigma, mu + 4*sigma, 1000)\nplt.plot(x, norm.pdf(x, mu, sigma), 'r', label='Theoretical PDF')\n\nplt.title(\"Generated Normal Distribution (μ=0, σ=1)\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Probability Density\")\nplt.legend()\nplt.grid(True)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:11.581542Z","iopub.execute_input":"2025-08-11T17:45:11.581780Z","iopub.status.idle":"2025-08-11T17:45:11.894285Z","shell.execute_reply.started":"2025-08-11T17:45:11.581759Z","shell.execute_reply":"2025-08-11T17:45:11.893314Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Module 3.2: Generating a theoretical poisson/gaussian distribution","metadata":{}},{"cell_type":"code","source":"#Poisson distribution\nfrom scipy.stats import poisson\n\nx = np.arange(0, 20)\npmf = poisson.pmf(x, mu=5)\nplt.bar(x, pmf)\nplt.title(\"Poisson Distribution (μ=5)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:11.895305Z","iopub.execute_input":"2025-08-11T17:45:11.895720Z","iopub.status.idle":"2025-08-11T17:45:12.328036Z","shell.execute_reply.started":"2025-08-11T17:45:11.895692Z","shell.execute_reply":"2025-08-11T17:45:12.327043Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Gaussian distribution\npdf=norm.pdf(x,mu,sigma)\nplt.bar(x,pdf)\nplt.title(\"Gaussian distribution\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:12.328858Z","iopub.execute_input":"2025-08-11T17:45:12.329109Z","iopub.status.idle":"2025-08-11T17:45:12.580092Z","shell.execute_reply.started":"2025-08-11T17:45:12.329090Z","shell.execute_reply":"2025-08-11T17:45:12.579098Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Module 4: Data transformations - demonstrating Log transformation\nPackages used: matplotlib, seaborn, scipy.stats\n\nDataset: heart-disease-uci/heart.csv","metadata":{}},{"cell_type":"code","source":"dc=pd.read_csv(\"/kaggle/input/heart-disease-data/heart_disease_uci.csv\")\ndc.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:45:12.581026Z","iopub.execute_input":"2025-08-11T17:45:12.581329Z","iopub.status.idle":"2025-08-11T17:45:12.605339Z","shell.execute_reply.started":"2025-08-11T17:45:12.581303Z","shell.execute_reply":"2025-08-11T17:45:12.604392Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset\ndc = pd.read_csv(\"/kaggle/input/heart-disease-data/heart_disease_uci.csv\")\n\n# Mean\nmean_chol = dc[\"chol\"].mean()\n\n# Median\nmedian_chol = dc[\"chol\"].median()\n\n# Standard deviation\nstd_chol = dc[\"chol\"].std()\n\nprint(\"Mean cholesterol:\", mean_chol)\nprint(\"Median cholesterol:\", median_chol)\nprint(\"Standard deviation:\", std_chol)\nskewness=(3*(mean_chol-median_chol))/(std_chol)\nprint(\"skewness:\",skewness)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Loading data\ndc=pd.read_csv(\"/kaggle/input/heart-disease-data/heart_disease_uci.csv\")\n\n#Plotting the original cholestrol distribution data\nsns.displot(dc[\"chol\"],kde=True)\nplt.title(\"DISTRIBUTION OF CHOLESTROL LEVEL\",fontsize=20)\nskewness=str(dc[\"chol\"].skew()) #measures the skewness\nkurtosis=str(dc[\"chol\"].kurt())\nplt.legend([skewness,kurtosis],title=(\"skewness and kurtosis\"))\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dc_valid = dc[dc[\"chol\"] > 0]  # remove invalid/missing cholesterol entries\nprint(\"Skewness:\", dc_valid[\"chol\"].skew())\nprint(\"Kurtosis:\", dc_valid[\"chol\"].kurt())\n\nsns.displot(dc_valid[\"chol\"], kde=True)\nplt.title(\"Cholesterol Distribution (Without Zero Values)\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Log transformation\nlog_target=np.log1p(dc[\"chol\"])\nax=sns.distplot(log_target)\nplt.title(\"DISTRIBUTION AFTER LOG TRANSFORMATION\",)\nskewness=str(log_target.skew())\nplt.legend([skewness],title=(\"skewness\"))\nplt.show()\n\n# Exercise 6: Repeat this for square root and other transformations.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sqrt_target=np.sqrt(dc[\"chol\"])\nplt.title(\"DISTRIBUTION AFTER SQUARERT TRANSFORMATION\",)\nskewness=str(sqrt_target.skew())\nplt.legend([skewness],title=(\"skewness\"))\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#reciprocol transformation \nreciprocal_target = 1 / (dc[\"chol\"] + 1)  \nsns.distplot(reciprocal_target)\nplt.title(\"DISTRIBUTION AFTER RECIPROCAL TRANSFORMATION\")\nplt.legend([reciprocal_target.skew()], title=\"skewness\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Assignment Exercises\n\n* Complete the six exercises given above as comments in various code blocks.\n* Repeat (all or most or as appropriate) the above workbook steps for data engineering and visualization for the 'students-random-number-dataset' already linked to this notebook.\n* Plot the distributions discussed in class, other than gaussian and poisson.\n* For the dataset in CELL 30-31 above, apply other transformations (not the Log transform) discussed in class.\n\nSubmission steps: \n* Clone and Edit this notebook to add all new exercises below this cell.\n* Once finished, connect this notebook to github.\n* Using the assignment link, join the github classroom by connecting your github account with already available name roster containing your institute email.\n* Commit!","metadata":{}}]}